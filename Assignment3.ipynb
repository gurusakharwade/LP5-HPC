{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jREurUWHlBB7",
        "outputId": "0210a20c-84ab-4d7e-ec82-88297e99de99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Wed_Apr_11_23:16:29_CDT_2018\n",
            "Cuda compilation tools, release 9.2, V9.2.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2DmGdUVme9l",
        "outputId": "2b27898f-8479-4810-b960-bb8d4043474b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-ruqrof3v\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-ruqrof3v\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4287 sha256=57ae5d2aa464a902dd5655c07e56c23ecbc3d8bc9b9dc848dab29f0d95559c7e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ti75e5nw/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xYC5DYznCER",
        "outputId": "4b1c4647-1bb1-4257-d64b-aa147831512f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cuda Max Reduce\n",
        "%%cu\n",
        "#include<stdio.h>\n",
        "#include<cuda.h>\n",
        "#include<stdlib.h>\n",
        "#include<time.h>\n",
        "\n",
        "__global__ void max1(int* input)\n",
        "{\n",
        "    const int tid = threadIdx.x;\n",
        "\n",
        "    auto step_size = 1;\n",
        "    int number_of_threads = blockDim.x;\n",
        "    int temp;\n",
        "\n",
        "    while (number_of_threads > 0)\n",
        "    {\n",
        "        if (tid < number_of_threads) // still alive?\n",
        "        {\n",
        "            const auto fst = tid * step_size * 2;\n",
        "            const auto snd = fst + step_size;\n",
        "            if (input[fst] < input[snd])\n",
        "            {\n",
        "                temp = input[fst];\n",
        "                input[fst] = input[snd];\n",
        "                input[snd] = temp;\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "        step_size <<= 1;\n",
        "        number_of_threads >>= 1;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const auto count = 8;\n",
        "    const int size = count * sizeof(int);\n",
        "    int h[] = {13, 65, 15, 14, 33, 2, 30, 8};\n",
        "\n",
        "    int* d;\n",
        "\n",
        "    cudaMalloc(&d, size);\n",
        "    cudaMemcpy(d, h, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    max1 <<<1, count / 2 >>>(d);\n",
        "\n",
        "    int result;\n",
        "    cudaMemcpy(&result, d, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    printf(\"Largest number is %d\\n\", result);\n",
        "\n",
        "    cudaFree(d);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok9yfpROCeKD",
        "outputId": "02bb9e87-441c-4dd6-b08e-9e1b7492e9f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Largest number is 65\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #cuda arrayAdd Reduce\n",
        " %%cu\n",
        " #include<stdio.h>\n",
        " #include<cuda.h>\n",
        " #include<stdlib.h>\n",
        " #include<time.h>\n",
        " \n",
        " __global__ void sum(int* input)\n",
        " {\n",
        " \tconst int tid = threadIdx.x;\n",
        " \n",
        " \tauto step_size = 1;\n",
        " \tint number_of_threads = blockDim.x;\n",
        " \n",
        " \twhile (number_of_threads > 0)\n",
        " \t{\n",
        " \t\tif (tid < number_of_threads) // still alive?\n",
        " \t\t{\n",
        " \t\t\tconst auto fst = tid * step_size * 2;\n",
        " \t\t\tconst auto snd = fst + step_size;\n",
        " \t\t\tinput[fst] += input[snd];\n",
        " \t\t}\n",
        " \t\t__syncthreads();\n",
        " \t\tstep_size <<= 1; \n",
        " \t\tnumber_of_threads >>= 1;\n",
        " \t}\n",
        " }\n",
        " \n",
        " int main()\n",
        " {\n",
        " \tconst auto count = 8;\n",
        " \tconst int size = count * sizeof(int);\n",
        " \tint h[] = {13, 27, 15, 14, 33, 2, 30, 8};\n",
        " \n",
        " \tint* d;\n",
        " \t\n",
        " \tcudaMalloc(&d, size);\n",
        " \tcudaMemcpy(d, h, size, cudaMemcpyHostToDevice);\n",
        " \n",
        " \tsum <<<1, count / 2 >>>(d);\n",
        " \n",
        " \tint result;\n",
        " \tcudaMemcpy(&result, d, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "  \t// cout << \"Sum is \" << result << endl;\n",
        "  printf(\"Sum is %d  \", result);\n",
        " \n",
        " \tgetchar();\n",
        " \n",
        " \tcudaFree(d);\n",
        " \t//delete[] h;\n",
        " \n",
        " \treturn 0;\n",
        " }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeBYFVNSDo3f",
        "outputId": "73ec851c-769f-4241-e78f-194e8d37d052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum is 142  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #cude min reduce\n",
        " %%cu\n",
        " #include<stdio.h>\n",
        " #include<cuda.h>\n",
        " #include<stdlib.h>\n",
        " #include<time.h>\n",
        " \n",
        " __global__ void min1(int* input)\n",
        " {\n",
        " \tconst int tid = threadIdx.x;\n",
        " \n",
        " \tauto step_size = 1;\n",
        " \tint number_of_threads = blockDim.x;\n",
        "  int temp;\n",
        " \n",
        " \twhile (number_of_threads > 0)\n",
        " \t{\n",
        " \t\tif (tid < number_of_threads) // still alive?\n",
        " \t\t{\n",
        " \t\t\tconst auto fst = tid * step_size * 2;\n",
        " \t\t\tconst auto snd = fst + step_size;\n",
        " \t\t\t//input[fst] += input[snd];\n",
        "       if (input[fst]>input[snd])\n",
        "       {\n",
        "           temp=input[fst];\n",
        "           input[fst]=input[snd];\n",
        "           input[snd]=temp;\n",
        "       }\n",
        " \t\t}\n",
        " \t\t__syncthreads();\n",
        " \t\tstep_size <<= 1; \n",
        " \t\tnumber_of_threads >>= 1;\n",
        " \t}\n",
        " }\n",
        " \n",
        " int main()\n",
        " {\n",
        " \tconst auto count = 8;\n",
        " \tconst int size = count * sizeof(int);\n",
        " \tint h[] = {13, 65, 15, 14, 33, 23, 30, 8};\n",
        " \n",
        " \tint* d;\n",
        "\n",
        " \tcudaMalloc(&d, size);\n",
        " \tcudaMemcpy(d, h, size, cudaMemcpyHostToDevice);\n",
        " \n",
        " \tmin1 <<<1, count / 2 >>>(d);\n",
        " \n",
        " \tint result;\n",
        " \tcudaMemcpy(&result, d, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "  \t// cout << \"Large no is %d \" << result << endl;\n",
        "  printf(\"Small no is %d  \", result);\n",
        " \n",
        " \tgetchar();\n",
        " \n",
        " \tcudaFree(d);\n",
        " \t//delete[] h;\n",
        " \n",
        " \treturn 0;\n",
        " }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9Xf63XDEBZK",
        "outputId": "066f9238-a918-4e8a-fb19-93a9d0ae5cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small no is 8  \n"
          ]
        }
      ]
    }
  ]
}